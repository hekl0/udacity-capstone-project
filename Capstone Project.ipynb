{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Project Title\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Import & Install required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "import configparser\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Read and Set AWS Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aws.cfg']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read('aws.cfg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "os.environ['AWS_ACCESS_KEY_ID'] = config['AWS']['AWS_ACCESS_KEY_ID']\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = config['AWS']['AWS_SECRET_ACCESS_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "s3_staging_area = config['S3']['STAGING_AREA']\n",
    "s3_dwh = config['S3']['DWH']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Create Spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder\\\n",
    "                    .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:2.7.0,saurfang:spark-sas7bdat:2.0.0-s_2.11\") \\\n",
    "                    .enableHiveSupport()\\\n",
    "                    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope\n",
    "We will create a fact table about US immigration from I94 immigration data and also make a dimension table about cities' population from US cities demographics data. The database will facilitate querying on immigration events and tracking the population.\n",
    "\n",
    "Technologies:\n",
    "+ Spark to process data\n",
    "+ AWS S3 as storage\n",
    "+ AWS EMR to create Spark cluster\n",
    "\n",
    "#### Describe and Gather Data \n",
    "I94 immigration data [[link](https://travel.trade.gov/research/reports/i94/historical/2016.html)], noticable columns:\n",
    "+ cicid\n",
    "+ i94yr: event year\n",
    "+ i94mon: event month\n",
    "+ i94port: destination city\n",
    "+ i94cit: origin country code of the immigrant\n",
    "+ i94mode: transportation mode code of the immigrant\n",
    "+ i94bir: age of the immigrant\n",
    "+ i94visa: purpose code for immigration\n",
    "+ visatype: visa type of the immigrant\n",
    "\n",
    "US cities demographics data [[link](https://public.opendatasoft.com/explore/dataset/us-cities-demographics/export/)], noticable columns:\n",
    "+ City: city name\n",
    "+ State Code\n",
    "+ Total Population\n",
    "+ Race\n",
    "+ Count\n",
    "\n",
    "City Code mapping (to map i94port to city):\n",
    "+ city_code\n",
    "+ city: city name\n",
    "+ state_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94port</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94bir</th>\n",
       "      <th>i94visa</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4084316.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>HHW</td>\n",
       "      <td>209.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4422636.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>MCA</td>\n",
       "      <td>582.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1195600.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>OGG</td>\n",
       "      <td>148.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5291768.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>297.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>985523.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>CHM</td>\n",
       "      <td>111.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cicid   i94yr  i94mon i94port  i94cit  i94mode  i94bir  i94visa  \\\n",
       "0  4084316.0  2016.0     4.0     HHW   209.0      1.0    61.0      2.0   \n",
       "1  4422636.0  2016.0     4.0     MCA   582.0      1.0    26.0      2.0   \n",
       "2  1195600.0  2016.0     4.0     OGG   148.0      1.0    76.0      2.0   \n",
       "3  5291768.0  2016.0     4.0     LOS   297.0      1.0    25.0      2.0   \n",
       "4   985523.0  2016.0     4.0     CHM   111.0      3.0    19.0      2.0   \n",
       "\n",
       "  visatype  \n",
       "0       WT  \n",
       "1       B2  \n",
       "2       WT  \n",
       "3       B2  \n",
       "4       WT  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('immigration_data_sample.csv')\n",
    "df[['cicid', 'i94yr', 'i94mon', 'i94port', 'i94cit', 'i94mode', 'i94bir', 'i94visa', 'visatype']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>MD</td>\n",
       "      <td>82463</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>MA</td>\n",
       "      <td>93629</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hoover</td>\n",
       "      <td>AL</td>\n",
       "      <td>84839</td>\n",
       "      <td>Asian</td>\n",
       "      <td>4759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rancho Cucamonga</td>\n",
       "      <td>CA</td>\n",
       "      <td>175232</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>24437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Newark</td>\n",
       "      <td>NJ</td>\n",
       "      <td>281913</td>\n",
       "      <td>White</td>\n",
       "      <td>76402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               City State Code  Total Population                       Race  \\\n",
       "0     Silver Spring         MD             82463         Hispanic or Latino   \n",
       "1            Quincy         MA             93629                      White   \n",
       "2            Hoover         AL             84839                      Asian   \n",
       "3  Rancho Cucamonga         CA            175232  Black or African-American   \n",
       "4            Newark         NJ            281913                      White   \n",
       "\n",
       "   Count  \n",
       "0  25924  \n",
       "1  58723  \n",
       "2   4759  \n",
       "3  24437  \n",
       "4  76402  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('us-cities-demographics.csv', delimiter=';')\n",
    "df[['City', 'State Code', 'Total Population', 'Race', 'Count']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_code</th>\n",
       "      <th>city</th>\n",
       "      <th>state_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ANC</td>\n",
       "      <td>Anchorage</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BAR</td>\n",
       "      <td>Baker Aaf - Baker Island</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DAC</td>\n",
       "      <td>Daltons Cache</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PIZ</td>\n",
       "      <td>Dew Station Pt Lay Dew</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DTH</td>\n",
       "      <td>Dutch Harbor</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  city_code                      city state_code\n",
       "0       ANC                 Anchorage         AK\n",
       "1       BAR  Baker Aaf - Baker Island         AK\n",
       "2       DAC             Daltons Cache         AK\n",
       "3       PIZ    Dew Station Pt Lay Dew         AK\n",
       "4       DTH              Dutch Harbor         AK"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('city_code_mapping.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Gather data to staging area on S3 Bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "* Gather I94 immigration data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_spark = spark.read.format('com.github.saurfang.sas.spark').load('./i94-immigration-data/i94_apr16_sub.sas7bdat')\n",
    "df_spark.write.parquet(os.path.join(s3_staging_area, \"sas_data\"), mode='overwrite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "* Gather US cities demographics data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_spark = spark.read.format('csv').option('header', 'true').option('delimiter', ';').load('us-cities-demographics.csv')\n",
    "new_column_name_list = list(map(lambda x: x.lower().replace(\" \", \"_\"), df_spark.columns))\n",
    "df_spark = df_spark.toDF(*new_column_name_list)\n",
    "df_spark.write.parquet(os.path.join(s3_staging_area, \"us_cities_demographics\"), mode='overwrite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "* Gather city code mapping data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_spark = spark.read.format('csv').option('header', 'true').load('city_code_mapping.csv')\n",
    "df_spark.write.parquet(os.path.join(s3_staging_area, \"city_code_mapping\"), mode='overwrite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "* Some rows in I94 immigration data don't have a valid i94port value\n",
    "\n",
    "#### Cleaning Steps\n",
    "* Remove rows in I94 immigration data which don't have a valid i94port value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_mapping = pd.read_csv(\"city_code_mapping.csv\")\n",
    "valid_list = df_mapping['city_code'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def clean_i94_immigration_data(df):\n",
    "    \"\"\"\n",
    "    Cleaning I94 Immigration table\n",
    "    \n",
    "    Parameter:\n",
    "    df: a Spark Dataframe\n",
    "    \n",
    "    Return:\n",
    "    a cleaned Spark Dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    return df.filter(df.i94port.isin(valid_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "Immigration Event Fact table:\n",
    "+ id\n",
    "+ year: event year\n",
    "+ month: event month\n",
    "+ city: destination city code\n",
    "+ origin: origin country code of the immigrant\n",
    "+ transportation: transportation mode code of the immigrant\n",
    "+ birth_year: age of the immigrant\n",
    "+ purpose: purpose code for immigration\n",
    "+ visatype: visa type of the immigrant\n",
    "\n",
    "City Dimension table:\n",
    "+ city_id\n",
    "+ city_name\n",
    "+ state\n",
    "+ population\n",
    "+ race\n",
    "+ count\n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "1. Read data from S3 Bucket\n",
    "2. Clean I94 immigration data\n",
    "3. Create Immigration Event Fact table and Write the result back to S3 Bucket\n",
    "4. Create City Dimension table and Write the result back to S3 Bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "immigration_events_table = spark.read.parquet(os.path.join(s3_staging_area, \"sas_data\"))\n",
    "immigration_events_table = clean_i94_immigration_data(immigration_events_table)\n",
    "immigration_events_table = immigration_events_table.selectExpr(\n",
    "    \"cicid AS id\",\n",
    "    'i94yr AS year',\n",
    "    'i94mon AS month',\n",
    "    'i94port AS city',\n",
    "    'i94cit AS origin',\n",
    "    'i94mode AS transportation',\n",
    "    'i94bir AS birth_year',\n",
    "    'i94visa AS purpose',\n",
    "    'visatype'\n",
    ")\n",
    "\n",
    "immigration_events_table.write.mode('append').parquet(os.path.join(s3_dwh, \"immigration_events_table\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "city_code_mapping_table = spark.read.parquet(os.path.join(s3_staging_area, \"city_code_mapping\"))\n",
    "cities_table = spark.read.parquet(os.path.join(s3_staging_area, \"us_cities_demographics\"))\n",
    "cities_table = cities_table.join(\n",
    "    city_code_mapping_table, \n",
    "    ['city', 'state_code']\n",
    ")\n",
    "cities_table.selectExpr(\n",
    "    'city_code AS city_id',\n",
    "    'city AS city_name',\n",
    "    'state_code AS state',\n",
    "    'total_population AS population',\n",
    "    'race',\n",
    "    'count'\n",
    ")\n",
    "\n",
    "cities_table.write.mode('overwrite').parquet(os.path.join(s3_dwh, \"city_table\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Check if the ETL is succesfully processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def data_quality_check(df):\n",
    "    \"\"\"\n",
    "    Run quality check on the input dataframe\n",
    "    \n",
    "    Paramater:\n",
    "    df: A Spark Dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    if df.count() == 0:\n",
    "        print(\"Data quality check failed!\")\n",
    "    else:\n",
    "        print(\"Data quality check succeed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data quality check succeed\n"
     ]
    }
   ],
   "source": [
    "data_quality_check(immigration_events_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data quality check succeed\n"
     ]
    }
   ],
   "source": [
    "data_quality_check(cities_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Data dictionary \n",
    "Immigration Event Fact table created from I94 immigration data:\n",
    "+ id: id of the event\n",
    "+ year: event year\n",
    "+ month: event month\n",
    "+ city: destination city code\n",
    "+ origin: origin country code of the immigrant\n",
    "+ transportation: transportation mode code of the immigrant\n",
    "+ birth_year: age of the immigrant\n",
    "+ purpose: purpose code for immigration\n",
    "+ visatype: visa type of the immigrant\n",
    "\n",
    "City Dimension table created from US cities demographics data and city code mapping table:\n",
    "+ city_id: id of the city\n",
    "+ city_name: name of the city\n",
    "+ state: state code of the city\n",
    "+ population: total population of the city\n",
    "+ race: human race\n",
    "+ count: the number of people from the race"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* Technologies:\n",
    "    - Spark to process data\n",
    "    - AWS S3 as storage\n",
    "    - AWS EMR for Spark cluster\n",
    "* The datawarehouse should be updated daily to keep track of immigration events\n",
    "* Future works:\n",
    "    - If the data was increased by 100x.: we should add more workers to the Spark cluster to efficiently process the data\n",
    "    - If the data populates a dashboard that must be updated on a daily basis by 7am every day: we should use a scheduler to schedule to run the ETL at night to meet the SLA\n",
    "    - If the database needed to be accessed by 100+ people: we will set the permission for them to access our S3 storage for datawarehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
